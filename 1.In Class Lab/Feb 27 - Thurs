#!/usr/bin/python3.8
#####################################
#
# Class 12: Numerical Differentiation II
# Author: M Joyce
#
#####################################

import numpy as np
import matplotlib.pyplot as plt
from math  import tanh, cosh

import sys
sys.path.append('.../')
file_save_path = sys.path.append('.../')
import my_functions_lib as mfl

## compute the instantaneous derivatives
## using the central difference approximation
## over the interval -2 to 2

x_lower_bound = -2.0
x_upper_bound = 2.0
N_samples = 100
h = (x_upper_bound-x_lower_bound)/N_samples
	

xdata = np.linspace(x_lower_bound, x_upper_bound, N_samples)

def central_diff(xdata,h):

	central_diff = []
	for x in xdata:
		central_difference = ( mfl.f(x + 0.5*h) - mfl.f(x - 0.5*h) ) / h
		central_diff.append(central_difference)
	return central_diff


def analytical_values(xdata):

	analytical_values = []
	for x in xdata:
		dfdx = mfl.df_dx_analytical(x)
		analytical_values.append(dfdx)
	return analytical_values

##########################


plt.plot(xdata, analytical_values(xdata), linestyle='-', color='black')
plt.plot(xdata, central_diff(xdata,h), "*", color="green", markersize=8, alpha=0.5, label ='best fit')
plt.plot(xdata, central_diff(xdata,1), "-", color="blue", markersize=8, alpha=0.5, label = 'h = 1')
plt.plot(xdata, central_diff(xdata,2), "-", color="red", markersize=8, alpha=0.5, label = 'h = 2')
plt.plot(xdata, central_diff(xdata,-16), "-", color="orange", markersize=8, alpha=0.5, label = 'h = -16')
plt.legend()
plt.show()
plt.close()
